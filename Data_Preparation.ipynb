{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bc5293-f763-44b2-8f18-0fc8adb72975",
   "metadata": {},
   "source": [
    "### Study of the effect of national factors on home prices in the US\n",
    "\n",
    "\n",
    "**Task:** Using publicly available data on the national factors that impact the supply and demand of homes in the US, build a data science model to study the effect of these variables on home prices.\n",
    "\n",
    "**Approach:** The following variables are chosen for the study:\n",
    "\n",
    "1. Unemployment Rate\n",
    "2. Employment Rate\n",
    "3. Per capita GDP\n",
    "4. Median Household Income\n",
    "5. Construction Prices\n",
    "6. CPI\n",
    "7. Interest Rates\n",
    "8. The number of new houses supplied\n",
    "9. Working Population\n",
    "10. Urban Population\n",
    "11. Percentage of population above 65\n",
    "12. Housing subsidies\n",
    "13. Number of Households\n",
    "\n",
    "As a proxy for home prices, the S&P **Case-Shiller Index** is used.\n",
    "\n",
    "**Note:** Most of the data is downloaded from [https://fred.stlouisfed.org/].\n",
    "\n",
    "Data for all the variables is downloaded, preprocessed, and combined to create a dataset using the **Extract Transform Load (ETL)** method. Data for different variables had different frequencies. So, to combine the data, the necessary interpolations are made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ecfe4-4790-4cc3-a7b5-3dc4576f1d8f",
   "metadata": {},
   "source": [
    "#### Importing neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7dda2d-0fc3-446b-9866-5a5d94f6b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796bb8f-d7ae-44d1-bcb2-46a0a780b875",
   "metadata": {},
   "source": [
    "#### Perform ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373272ae-ed2e-4fb9-9c6c-490f518e9e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the CASE-SHILLER Index:-  (252, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CSUSHPISA</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Per_Capita_GDP</th>\n",
       "      <th>working_age_pop</th>\n",
       "      <th>Houses</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>EmpRate</th>\n",
       "      <th>Cons_Material</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>urban_pop_us</th>\n",
       "      <th>Num_Households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>Subsidy</th>\n",
       "      <th>old_age_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>301.596</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>65569.000000</td>\n",
       "      <td>2.073941e+08</td>\n",
       "      <td>8.7</td>\n",
       "      <td>295.320</td>\n",
       "      <td>3.7</td>\n",
       "      <td>71.466900</td>\n",
       "      <td>342.753</td>\n",
       "      <td>2.33</td>\n",
       "      <td>83.1</td>\n",
       "      <td>131202.0</td>\n",
       "      <td>74580.0</td>\n",
       "      <td>48.021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>299.380</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>65676.000000</td>\n",
       "      <td>2.074743e+08</td>\n",
       "      <td>9.7</td>\n",
       "      <td>296.539</td>\n",
       "      <td>3.5</td>\n",
       "      <td>71.444231</td>\n",
       "      <td>336.464</td>\n",
       "      <td>2.56</td>\n",
       "      <td>83.1</td>\n",
       "      <td>131202.0</td>\n",
       "      <td>74580.0</td>\n",
       "      <td>48.021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>298.922</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>65783.000000</td>\n",
       "      <td>2.074563e+08</td>\n",
       "      <td>9.7</td>\n",
       "      <td>297.987</td>\n",
       "      <td>3.7</td>\n",
       "      <td>71.247799</td>\n",
       "      <td>333.796</td>\n",
       "      <td>3.08</td>\n",
       "      <td>83.1</td>\n",
       "      <td>131202.0</td>\n",
       "      <td>74580.0</td>\n",
       "      <td>48.021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>298.312</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>65881.333333</td>\n",
       "      <td>2.075097e+08</td>\n",
       "      <td>9.4</td>\n",
       "      <td>298.598</td>\n",
       "      <td>3.6</td>\n",
       "      <td>71.323036</td>\n",
       "      <td>330.369</td>\n",
       "      <td>3.78</td>\n",
       "      <td>83.1</td>\n",
       "      <td>131202.0</td>\n",
       "      <td>74580.0</td>\n",
       "      <td>48.021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>297.471</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>65979.666667</td>\n",
       "      <td>2.075066e+08</td>\n",
       "      <td>8.5</td>\n",
       "      <td>298.990</td>\n",
       "      <td>3.5</td>\n",
       "      <td>71.575987</td>\n",
       "      <td>326.449</td>\n",
       "      <td>4.10</td>\n",
       "      <td>83.1</td>\n",
       "      <td>131202.0</td>\n",
       "      <td>74580.0</td>\n",
       "      <td>48.021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  CSUSHPISA  Year  Month  Per_Capita_GDP  working_age_pop  \\\n",
       "247 2022-08-01    301.596  2022      8    65569.000000     2.073941e+08   \n",
       "248 2022-09-01    299.380  2022      9    65676.000000     2.074743e+08   \n",
       "249 2022-10-01    298.922  2022     10    65783.000000     2.074563e+08   \n",
       "250 2022-11-01    298.312  2022     11    65881.333333     2.075097e+08   \n",
       "251 2022-12-01    297.471  2022     12    65979.666667     2.075066e+08   \n",
       "\n",
       "     Houses      CPI  UNRATE    EmpRate  Cons_Material  FEDFUNDS  \\\n",
       "247     8.7  295.320     3.7  71.466900        342.753      2.33   \n",
       "248     9.7  296.539     3.5  71.444231        336.464      2.56   \n",
       "249     9.7  297.987     3.7  71.247799        333.796      3.08   \n",
       "250     9.4  298.598     3.6  71.323036        330.369      3.78   \n",
       "251     8.5  298.990     3.5  71.575987        326.449      4.10   \n",
       "\n",
       "     urban_pop_us  Num_Households  median_income  Subsidy  old_age_pop  \n",
       "247          83.1        131202.0        74580.0   48.021         17.1  \n",
       "248          83.1        131202.0        74580.0   48.021         17.1  \n",
       "249          83.1        131202.0        74580.0   48.021         17.1  \n",
       "250          83.1        131202.0        74580.0   48.021         17.1  \n",
       "251          83.1        131202.0        74580.0   48.021         17.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading CASE-SHILLER Index into a dataframe\n",
    "df_CS = pd.read_csv(\"prepared_dataset.csv\")\n",
    "\n",
    "# Changing dtype of date column\n",
    "df_CS[\"DATE\"] = pd.to_datetime(df_CS[\"DATE\"])\n",
    "\n",
    "# Selecting data till JULY 2023\n",
    "mask = df_CS[\"DATE\"] <= \"2023-07-01\"\n",
    "df_CS = df_CS[mask]\n",
    "\n",
    "#Resetting Index\n",
    "df_CS.reset_index(inplace = True)\n",
    "df_CS.drop(columns = [\"index\"], inplace = True)\n",
    "\n",
    "# Creating \"Year\" and \"Month\" columns\n",
    "df_CS[\"Year\"] = pd.DatetimeIndex(df_CS[\"DATE\"]).year\n",
    "df_CS[\"Month\"] = pd.DatetimeIndex(df_CS[\"DATE\"]).month\n",
    "print(\"Shape of the CASE-SHILLER Index:- \", df_CS.shape)\n",
    "df_CS.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee173678-0f21-49fd-85c1-2f900346a578",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UNRATE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reading Unemployment Rate Data into a dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_unemp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNRATE.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_unemp\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;241m259\u001b[39m], inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnemployment Rate Data:- \u001b[39m\u001b[38;5;124m\"\u001b[39m, df_unemp\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UNRATE.csv'"
     ]
    }
   ],
   "source": [
    "# Reading Unemployment Rate Data into a dataframe\n",
    "df_unemp = pd.read_csv(\"UNRATE.csv\")\n",
    "df_unemp.drop([259], inplace = True)\n",
    "print(\"Unemployment Rate Data:- \", df_unemp.shape)\n",
    "df_unemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5a584-37c0-48fa-99f2-ccf52c121fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Employment Rate Data into a dataframe\n",
    "df_emp = pd.read_csv(\"EMPRATE.csv\")\n",
    "df_emp = df_emp.rename(columns={'LREM64TTUSM156S': 'EmpRate'})\n",
    "df_emp.drop([259], inplace = True)\n",
    "print(\"shape of the Employment Rate Data:- \", df_emp.shape)\n",
    "df_emp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecc0d7-f7c3-4e59-ae9f-6a209473b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Per Capita GDP Data into a dataframe\n",
    "df_pcgdp = pd.read_csv(\"GDP_per_capita.csv\", names = [\"DATE\", \"A939RX0Q048SBEA\"], skiprows = 1)\n",
    "df_pcgdp = df_pcgdp.rename(columns={'A939RX0Q048SBEA': 'Per_Capita_GDP'})\n",
    "print(\"Shape of the Per Capita GDP Data:- \", df_pcgdp.shape)\n",
    "df_pcgdp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2eb2f0-0f9d-4a7f-bf3a-aa3b22d91338",
   "metadata": {},
   "source": [
    "The data is quarterly. We will impute for other months using linear interpolation after we create the final dataframe combining all the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32ea4d-4402-4ebd-a5e3-05cf4669acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interest Rate Data\n",
    "df_Fed_rate = pd.read_csv(\"FEDFUNDS.csv\").drop([259])\n",
    "print(\"Shape of the Interest rate data:- \",df_Fed_rate.shape)\n",
    "df_Fed_rate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503e0bb-029f-471f-8297-fe59db36bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Construction Material Data into a dataframe\n",
    "df_cons_price_index = pd.read_csv(\"construction_price_ppi.csv\", names = [\"DATE\", \"WPUSI012011\"], skiprows = 1)\n",
    "df_cons_price_index = df_cons_price_index.rename(columns={'WPUSI012011': 'Cons_Material'})\n",
    "df_cons_price_index.drop([259], inplace = True)\n",
    "print(\"Shape of the Construction Material Data:- \", df_cons_price_index.shape)\n",
    "df_cons_price_index.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb75ff-eed8-40d8-b464-ba08d9f6d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer Price Index\n",
    "df_CPI = pd.read_csv(\"CPIAUCSL.csv\", names = [\"DATE\", \"CPIAUCSL\"], skiprows = 1).drop([259])\n",
    "df_CPI = df_CPI.rename(columns={'CPIAUCSL': 'CPI'})\n",
    "print(\"Shape of the Consumer Price Index:- \", df_CPI.shape)\n",
    "df_CPI.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfee5a1-90fd-49c1-9268-16193a249323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly new house supply\n",
    "df_house = pd.read_csv(\"monthly_house_supply.csv\", names = [\"DATE\", \"MSACSR\"], skiprows = 1).drop([259])\n",
    "df_house = df_house.rename(columns={'MSACSR': 'Houses'})\n",
    "print(\"Shape of the monthly house supply data:- \", df_house.shape)\n",
    "df_house.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfadd45-ab0b-43a8-ac83-788376407d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population above 65\n",
    "\n",
    "df_oldpop = pd.read_csv(\"old_age_pop.csv\", names = [\"DATE\", \"old_age_pop\"], skiprows = 1)\n",
    "df_oldpop['DATE'] = pd.to_datetime(df_oldpop['DATE'], format=\"%d-%m-%Y\").dt.strftime(\"%Y-%m-%d\")\n",
    "print(\"Shape of the population data age above 65:- \", df_oldpop.shape)\n",
    "df_oldpop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61430632-8b08-4d4b-89ad-1536d1dbe6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urban Population Percent\n",
    "\n",
    "df_urban = pd.read_csv(\"urban_pop.csv\")\n",
    "df_urban['DATE'] = pd.to_datetime(df_urban['DATE'], format=\"%d-%m-%Y\").dt.strftime(\"%Y-%m-%d\")\n",
    "print(\"Shape of the urban population percent data:- \", df_urban.shape)\n",
    "df_urban.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5507d-b3a2-4b18-839f-c8dda5eaeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing Subsidies\n",
    "\n",
    "df_subsidy = pd.read_csv(\"housing_subsidies.csv\", names = [\"DATE\", \"Subsidy\"], skiprows = 1)\n",
    "print(\"Shape of the housing subsidies:- \", df_subsidy.shape)\n",
    "df_subsidy.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f00aeb-d491-42cc-9cf1-f605e2c7cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working age population\n",
    "\n",
    "df_working = pd.read_csv(\"working_age_population.csv\", names = [\"DATE\", \"LFWA64TTUSM647S\"], skiprows = 1).drop([259])\n",
    "df_working = df_working.rename(columns={'LFWA64TTUSM647S': 'working_age_pop'})\n",
    "print(\"Shape of the working age population:- \", df_working.shape)\n",
    "df_working.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320125b7-9a44-4a4d-9a91-5454ee57df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Median Household Income\n",
    "\n",
    "df_income = pd.read_csv(\"median_household_income.csv\", names = [\"DATE\", \"MEHOINUSA672N\"], skiprows = 1)\n",
    "df_income = df_income.rename(columns={'MEHOINUSA672N': 'median_income'})\n",
    "print(\"Shape of the median household income data:- \", df_income.shape)\n",
    "df_income.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2c93b-1b62-4ed5-a973-761f4a718850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of households\n",
    "\n",
    "df_households = pd.read_csv(\"household.csv\", names = [\"DATE\", \"TTLHH\"], skiprows = 1)\n",
    "df_households = df_households.rename(columns={'TTLHH': 'Num_Households'})\n",
    "print(\"Shape of the total households data:- \", df_households.shape)\n",
    "df_households.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b135f16-7f50-4130-a0e1-1de0ced58c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Per Capita GDP (Quarterly data)\n",
    "df_pcgdp[\"DATE\"] = pd.to_datetime(df_pcgdp[\"DATE\"])\n",
    "df_CS = pd.merge(df_CS,df_pcgdp, how = \"left\")\n",
    "df_CS.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd07fbf-1cab-434c-b29d-8151db4feff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concating dataframes having monthly data to create one dataframe\n",
    "df = pd.DataFrame()\n",
    "df_bymonth = [df_CS, df_working, df_house, df_CPI, df_unemp, df_emp, df_cons_price_index, df_Fed_rate]\n",
    "for df1 in df_bymonth:\n",
    "    df1[\"DATE\"] = pd.to_datetime(df1[\"DATE\"])\n",
    "    df1 = df1.set_index(\"DATE\")\n",
    "    df = pd.concat([df,df1], axis = 1)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24087f0c-a725-40e6-8078-cfc1adf2a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging other dataframes \n",
    "others = [df_urban, df_households, df_income, df_subsidy, df_oldpop]\n",
    "for df1 in others:\n",
    "    if \"Year\" not in df1.columns:\n",
    "        df1[\"Year\"] = pd.DatetimeIndex(df1[\"DATE\"]).year\n",
    "        df1.set_index(\"DATE\", inplace = True)\n",
    "        df = pd.merge(df, df1, how = \"left\", on = \"Year\")\n",
    "    else:\n",
    "        df1.set_index(\"DATE\", inplace = True)\n",
    "        df = pd.merge(df, df1, how = \"left\", on = \"Year\")\n",
    "df[\"DATE\"] = df_CS[\"DATE\"]\n",
    "df.set_index(\"DATE\", inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aae2ab-006c-4543-a4ac-322e739dad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960c0a0-e480-4c8d-ad0f-b9a9797143db",
   "metadata": {},
   "source": [
    "Check missing values (NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f73dd1-9f66-4a09-aa28-a98bfdcfe103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ecbb6-d720-4b2c-8a54-ebd31e4445d9",
   "metadata": {},
   "source": [
    "The \"Per_Capita_GDP\" column has missing values because the data was quarterly. The missing values in the other columns are due to the unavailability of fresh data. We will first fill in the missing values in the \"Per_Capita_GDP\" column using linear interpolation. We will drop the rows with missing values in the other columns. This means that we will use data from 2002 to 2022.\n",
    "\n",
    "**Interpolation:**\n",
    "\n",
    "Interpolation is a mathematical technique used to estimate values that are missing in a dataset based on the values of neighboring data points. It calculates intermediate values based on the existing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff19d0d-2e0d-47c1-901f-6008900bd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values in the Per_Capita_GDP column using linear interpolation\n",
    "df[\"Per_Capita_GDP\"] = df[\"Per_Capita_GDP\"].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9592356-38d6-4c06-809b-26b32b91bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638767c-2548-4889-9d9f-65c777cb6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28f993-b4ff-420f-8d18-21260e467a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41794f2d-3e76-4e67-b2df-fd3ba611a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9654dc-1977-40a1-9ece-c731d94bc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the dataframe after preprocessing:- \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d99b8-043a-4c5d-af0c-5bc3ea56d424",
   "metadata": {},
   "source": [
    "This is our preprocessed datset. Let's save it as \"prepared_dataset.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660543a-768f-4980-9c22-4675d1a4619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"prepared_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944bf85-c5e9-4967-b2b9-ee910f9e01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_house_price_df = pd.read_csv(\"prepared_dataset.csv\").set_index(\"DATE\")\n",
    "us_house_price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab619af-16fb-4b68-8a07-328374d1712d",
   "metadata": {},
   "source": [
    "## To be continued..........."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
